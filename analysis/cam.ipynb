{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from functools import partial\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.benchmarks import SplitTinyImageNet\n",
    "\n",
    "# Get the parent directory of the current notebook\n",
    "parent_dir = Path.cwd().parent\n",
    "\n",
    "# Add the parent directory (which contains the svcca directory) to the Python path\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "from analysis.args import (\n",
    "    MODEL_DIR,\n",
    "    LAYERS,\n",
    "    ALGOS,\n",
    "    # LOAD_EXPERIENCES,\n",
    "    NUM_EXPERIENCES_TRAINED_ON,\n",
    "    TRUNCATE\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate_experiences,\n",
    "    adapt_model,\n",
    "    model_loader,\n",
    "    strategy_builder,\n",
    "    StrategiesEnum,\n",
    "    DataStreamEnum\n",
    ")\n",
    "\n",
    "from training.args import lwf_args, mas_args, naive_args\n",
    "from training.models.models import MultiHeadVGGSmall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "class ModelWrapper: \n",
    "    def __init__(self, model, task_labels):\n",
    "        self.model = model\n",
    "        self.task_labels = task_labels\n",
    "        \n",
    "    def __getattr__(self, attr):\n",
    "        if attr == \"forward\":\n",
    "            return self.forward_wrapper\n",
    "        return getattr(self.model, attr)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward_wrapper(x)\n",
    "    \n",
    "    def forward_wrapper(self, x):\n",
    "        return self.model.forward(x, self.task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"test\"\n",
    "SAVE_CAM_DIR = \"test_cams\" if SPLIT == \"test\" else \"train_cams\"\n",
    "LOAD_EXPERIENCES = list(range(9,10))\n",
    "EVALUATE_EXPERIENCES = list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cam_dict(model, inputs, name, model_id, exp_id):\n",
    "    cam_extractor = GradCAM(model, target_layer=LAYERS)\n",
    "    out = model(inputs) \n",
    "    cam = cam_extractor(list(out.argmax(dim=1)), out)     \n",
    "    cam = [layer_cam.tolist() for layer_cam in cam]\n",
    "    cam_dict = dict(zip(LAYERS, cam))\n",
    "    with open(f'../{SAVE_CAM_DIR}/{name}_cam_on_model_{model_id}_exp_{exp_id}.json', 'w') as f:\n",
    "        json.dump(cam_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Split benchmark\n",
    "benchmark = SplitTinyImageNet(\n",
    "    NUM_EXPERIENCES_TRAINED_ON, return_task_id=True, dataset_root=None)\n",
    "\n",
    "# Generate list of experiences\n",
    "if (DataStreamEnum[SPLIT] == DataStreamEnum.train):\n",
    "    stream = benchmark.train_stream\n",
    "elif (DataStreamEnum[SPLIT] == DataStreamEnum.test):\n",
    "    stream = benchmark.test_stream\n",
    "\n",
    "experiences = generate_experiences(\n",
    "    stream=stream, n_experiences=benchmark.n_experiences)\n",
    "\n",
    "# Directory where all models are saved\n",
    "lwf_dir = Path(f\"../{MODEL_DIR}/lwf_150_saved_models\")\n",
    "mas_dir = Path(f\"../{MODEL_DIR}/mas_150_saved_models\")\n",
    "naive_dir = Path(f\"../{MODEL_DIR}/naive_150_saved_models\")\n",
    "\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "base_model = MultiHeadVGGSmall(n_classes=200)\n",
    "\n",
    "# Iterate through all experiences to load\n",
    "for load_experience in LOAD_EXPERIENCES:\n",
    "\n",
    "    # Adapt base model with experiences\n",
    "    if (load_experience > 0):\n",
    "        adapt_model(base_model, experiences)\n",
    "\n",
    "    # Load trained model paths\n",
    "    pattern = f\"*{load_experience}\"\n",
    "    lwf_path = list(lwf_dir.glob(pattern))[0]\n",
    "    mas_path = list(mas_dir.glob(pattern))[0]\n",
    "    naive_path = list(naive_dir.glob(pattern))[0]\n",
    "\n",
    "    # Instantiate trained models\n",
    "    lwf_model_partial = partial(ModelWrapper, model=model_loader(base_model=base_model, path=lwf_path))\n",
    "    mas_model_partial = partial(ModelWrapper, model=model_loader(base_model=base_model, path=mas_path))\n",
    "    naive_model_partial = partial(ModelWrapper, model=model_loader(base_model=base_model, path=naive_path))\n",
    "\n",
    "    # Evaluation experiences\n",
    "    for eval_exp in EVALUATE_EXPERIENCES:\n",
    "        \n",
    "        exp = experiences[eval_exp]\n",
    "        labels = exp.classes_in_this_experience\n",
    "        targets = [sample[1] for sample in exp.dataset]\n",
    "        sample_indices = [targets.index(label) for label in labels]\n",
    "        subset = exp.dataset.subset(sample_indices)\n",
    "        dataloader = DataLoader(subset, batch_size=100)\n",
    "        \n",
    "        inputs, _, _ = next(iter(dataloader))\n",
    "        \n",
    "        # LWF\n",
    "        names = [\"lwf\", \"mas\", \"naive\"]\n",
    "        models = [lwf_model_partial(task_labels=exp.task_label), mas_model_partial(task_labels=exp.task_label), naive_model_partial(task_labels=exp.task_label)]\n",
    "        \n",
    "        for i in range(len(models)):\n",
    "            make_cam_dict(model=models[i], inputs=inputs, name=names[i], model_id=load_experience, exp_id=eval_exp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "map-transform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
